{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "11NgcqUdYPVPE74KlDreN1xeSIsO5EVrI",
      "authorship_tag": "ABX9TyPP13yK8PEquuL1Csnhc89F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varu-srma-0107/Machine-learning/blob/main/Mnist_resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRdYXxsCQ8aR"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "from tensorflow import keras\n",
        "\n",
        "from fastai import *\n",
        "from fastai.vision import *\n",
        "from fastai.vision.all import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Dataset/archive/mnist_train.csv\")"
      ],
      "metadata": {
        "id": "EpPtXeyKREaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_00_qvLRICe",
        "outputId": "43d3314e-55d8-45c3-c732-146b1e96c93a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train) , (X_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCR8bFSCZULK",
        "outputId": "e922d2e0-96a1-4e09-b54a-5fb219ee0829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train).reshape(-1,28, 28)\n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "id": "kDtpkWgvYthL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN9nUzELYtkC",
        "outputId": "54740fbf-0fe7-4e47-a982-53613f1722c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.stack((X_train,)*3, axis=-1)"
      ],
      "metadata": {
        "id": "5qVIU6DxYtuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5xdyGo0Z0ZV",
        "outputId": "a504de89-d52c-47aa-8c99-d50166e99756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_imgs(path:Path, data, labels):\n",
        "    for label in np.unique(labels):\n",
        "        (path/str(label)).mkdir(parents=True,exist_ok=True)\n",
        "    for i in range(len(data)):\n",
        "        if(len(labels)!=0):\n",
        "            imageio.imsave( str( path/str(labels[i])/(str(i)+'.jpg') ), data[i])\n",
        "        else:\n",
        "            imageio.imsave( str( path/(str(i)+'.jpg') ), data[i])"
      ],
      "metadata": {
        "id": "GmGz-nMHZ0dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_imgs(Path('/data/digits'),X_train,y_train)"
      ],
      "metadata": {
        "id": "rK7cF4JLZ0hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('total classes :', len(os.listdir('/data/digits')))\n",
        "print('Images with label 1: ', len(os.listdir('/data/digits/1')))\n",
        "\n",
        "print('Image names with label 1')\n",
        "print(os.listdir('/data/digits/1')[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whC1IU0EZ0lh",
        "outputId": "0e7d9d5e-e89d-4ccf-d4d8-91f52264b58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total classes : 10\n",
            "Images with label 1:  6742\n",
            "Image names with label 1\n",
            "['46842.jpg', '45665.jpg', '32765.jpg', '16876.jpg', '31784.jpg', '42380.jpg', '5428.jpg', '39986.jpg', '6423.jpg', '51417.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50"
      ],
      "metadata": {
        "id": "Dt5K6PIFaqxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "import tensorflow as tf\n",
        "\n",
        "train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.15)\n",
        "train_generator = train_datagen.flow_from_directory('/data/digits', class_mode='categorical', subset='training')\n",
        "valid_generator = train_datagen.flow_from_directory('/data/digits', class_mode='categorical', subset='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlw4_HFPZ0pJ",
        "outputId": "bc0b8b3a-2571-4c13-86f2-b422ae57a2fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 51005 images belonging to 10 classes.\n",
            "Found 8995 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = train_generator[0]\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr16rDobZ0wN",
        "outputId": "a515de6d-a121-4efa-e3e2-2b71d8e3b19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 256, 256, 3)\n",
            "(32, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "BJOHWfKCRLgl",
        "outputId": "df9f2d6a-20cd-4ff0-d5d7-9ca5204ff021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6a4dbcfdc0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_weights_path = r'C:\\Users\\LENOVO\\Downloads\\resnet50_weights_tf_dim_ordering_tf_kernels_notop'"
      ],
      "metadata": {
        "id": "hHQ3mL9KRQmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "model = Sequential()\n",
        "\n",
        "model.add(ResNet50(include_top = False, pooling = 'avg', weights = 'imagenet'))\n",
        "\n",
        "# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n",
        "model.add(Dense(10, activation = 'softmax'))\n",
        "\n",
        "# Say not to train first layer (ResNet) model as it is already trained\n",
        "model.layers[0].trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNGMczvPRSzH",
        "outputId": "c2cb4fe7-55d7-4b42-dc4e-460f5fe51155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReIpCxydSbj2",
        "outputId": "4f05d1e6-9ca5-4d75-a9c3-8b4f606bcbf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,608,202\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "pogHyw9jSeaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(generator=train_generator,epochs=10,validation_data=valid_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PHvmVoXShtK",
        "outputId": "62a45dbe-3532-4d5e-8876-8eac0b7add16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-d238ee210fa0>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator=train_generator,epochs=10,validation_data=valid_generator)\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1594/1594 [==============================] - 673s 418ms/step - loss: 0.3576 - accuracy: 0.9035 - val_loss: 0.1729 - val_accuracy: 0.9539\n",
            "Epoch 2/10\n",
            "1594/1594 [==============================] - 673s 422ms/step - loss: 0.1475 - accuracy: 0.9582 - val_loss: 0.1352 - val_accuracy: 0.9601\n",
            "Epoch 3/10\n",
            "1594/1594 [==============================] - 670s 420ms/step - loss: 0.1136 - accuracy: 0.9670 - val_loss: 0.1095 - val_accuracy: 0.9679\n",
            "Epoch 4/10\n",
            "1594/1594 [==============================] - 670s 420ms/step - loss: 0.0960 - accuracy: 0.9716 - val_loss: 0.1132 - val_accuracy: 0.9652\n",
            "Epoch 5/10\n",
            "1594/1594 [==============================] - 669s 420ms/step - loss: 0.0839 - accuracy: 0.9752 - val_loss: 0.0883 - val_accuracy: 0.9728\n",
            "Epoch 6/10\n",
            "1594/1594 [==============================] - 670s 421ms/step - loss: 0.0752 - accuracy: 0.9775 - val_loss: 0.0959 - val_accuracy: 0.9727\n",
            "Epoch 7/10\n",
            "1594/1594 [==============================] - 670s 420ms/step - loss: 0.0697 - accuracy: 0.9791 - val_loss: 0.0895 - val_accuracy: 0.9737\n",
            "Epoch 8/10\n",
            "1594/1594 [==============================] - 670s 420ms/step - loss: 0.0634 - accuracy: 0.9807 - val_loss: 0.0859 - val_accuracy: 0.9737\n",
            "Epoch 9/10\n",
            "1594/1594 [==============================] - 670s 420ms/step - loss: 0.0597 - accuracy: 0.9812 - val_loss: 0.0804 - val_accuracy: 0.9742\n",
            "Epoch 10/10\n",
            "1594/1594 [==============================] - 670s 420ms/step - loss: 0.0543 - accuracy: 0.9835 - val_loss: 0.0798 - val_accuracy: 0.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6a4d8a6070>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}